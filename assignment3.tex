\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{url,paralist,xspace,textcomp}
\usepackage{enumitem}
\usepackage{fullpage}
%%\usepackage{times}

\title{Advanced Programming\\ Assignment 3: Remember that song?}
\author{Thomas Bracht Laumann Jespersen\\ \url{ntl316@alumni.ku.dk} \and Marco Eilers\\ \url{dbk726@alumni.ku.dk} }

\usepackage{listings}
\lstset{basicstyle=\ttfamily\scriptsize}


\begin{document}
\maketitle

The code is split up into three modules: The module \texttt{mr}
 contains the general purpose Map-Reduce skeleton, \texttt{mr\_wc} contains functions for working with the MXM dataset
 (using said skeleton) and \texttt{mr\_test} contains
  unit tests for both of the aforementioned modules. The file \texttt{read\_mxm.erl} contains the provided code for reading the dataset, and for testing purposes we expect the file \texttt{mxm\_dataset\_test.txt} as well as a much smaller set (\texttt{mini\_dataset.txt}) to be in the current folder. If word stems are to be looked up, a file formatted like \texttt{stemmed\_words.txt} from the mxm dataset website needs to be present as well.

\section*{Code description}
We have implemented or completed the following functionality:
\begin{description}
\item[Map-Reduce] We've ``filled'' in the handed-out \texttt{mr-skel.erl}, so our API is no different from the recommended API, except for one tiny extension: We also export a function \texttt{status/1} that takes a pid and writes the status of the currently running map-reducer.
  
  The internal details of the implementation are as follows:
  \begin{itemize}
  \item \texttt{start/1} checks whether the given argument is larger than $0$, and returns \texttt{fail} if it isn't
  \item When \texttt{init/1} spawns its $N$ mappers, it needs to supply (aside from the pid of a reducer) a function for the mapper to use. Since we at initalization time don't have such a function, we provide a default (the \texttt{id} function). One could also have used an atom here \texttt{no\_function} (or something) to indicate that the mapper has not been handed a function.
  \item The \texttt{Missing} parameter in \texttt{gather\_data\_from\_mappers/3}, we've used as a simple counter, so once we start gathering data from the mappers we simply hand it the length of the input. This is very simplistic and probably not very robust, but it has worked for all our purposes.
  \item The \texttt{receive} section in \texttt{gather\_data\_from\_mappers} also has a timeout of five seconds, in case one of the mappers died, we don't stall forever, but instead write a message including the \texttt{Acc} and \texttt{Missing} parameters. This way it is quick to see how many pieces of data we're missing. Finally, we return \texttt{timeout}.
   \item The \texttt{mapper\_loop} is very simple in its implementation, it responds to the messages \texttt{stop}, \texttt{data} and \texttt{setup}. Given \texttt{\{data, D\}} it applies its function and sends the result asynchronously to the reducer. When given \texttt{\{setup, NewFun\}} it simply replaces the function it had with \texttt{NewFun}. An interesting observation about the \texttt{mapper\_loop} is that it only communicates asynchronously (and is only communicated with asynchronously).
  \end{itemize}
\item[Total number of words in songs]\hfill
  \begin{itemize}
  \item Mapper: Given a \texttt{Track}, parses it with \texttt{read\_mxm:parse\_track/1} to get the list of \texttt{WordBags}, then it folds up the list summing the word count for each word bag.
  \item Reducer: Given the sum of words for a single track it adds it to a total sum.
  \end{itemize}
  When all tracks have been processed the sum returned by the reducer is the total sum of words in all the songs (assuming we start from $0$).

  One could argue that the job of the mapper is only to unpack the given \texttt{Track} and pass the list of words to the reducer to sum, but given that we have more mappers than reducers, it seems sensible to have the mapper do as much work as possible.
\item[Compute averages]\hfill
  \begin{itemize}
  \item Mapper: Does almost the same as the previous exercise, but also counts the number of word bags for a track. The input to the reducer is then a tuple \texttt{\{NDiffWords, NWords\}}.
  \item Reducer: Needs to calculate a running average. It does this by keeping track of three numbers: The average number of different words (so far), the average number of words (so far) and the number of tracks it has processed (so far).

    When given \texttt{\{NDiffWords, NWords\}} it recomputes the total number of different words and the total number of words, adding in the new numbers and adding one to the number of tracks processed. The new averages are then the totals divided by the new number of tracks.
  \end{itemize}
  This implementation is not very efficient, because we're constantly multiplying and dividing, and we cannot guarantee a slight skewing in this way of processing. A more robust method would be to also keep track of the totals.
\item[Grep]
  The \texttt{grep}, besides accepting a tuple of \texttt{\{Words, Tracks\}} (output by \texttt{read\_mxm:from\_file/1}), also expects a \texttt{Word} to look for. To speed things up, it first looks up the index of the word in the the list of words.
  \begin{itemize}
    \item Mapper: Given a \texttt{Track}, unpacks it to get the \texttt{MXMID} and \texttt{WordBags}. Then it unzips the word bags to get a list of indices \texttt{Idxs}. The input to the reducer is then \texttt{\{MXMID, Idxs\}}.
    \item Reducer: Given that we've already found the index of the word we're looking for, we just need to see if this index is a member of the given list of indices. If it is, we add \texttt{MXMID} to an accumulated list of tracks (starting from the empty list).
  \end{itemize}
  The motivation for first looking up the word index, is that otherwise we'd have to look up every single index to see if the resulting is the word we're looking for (this was our initial implementation and it was observably slower).
\item[Reverse index]
  The \texttt{reverse\_index} computes a dictionary (using the module \texttt{dict}), mapping words to the tracks in which they occur.
  \begin{itemize}
    \item Mapper: Unpacks a given \texttt{Track}, unzips the word bags to get a list of indices. Then it maps every index to a word in \texttt{Words} and passes \texttt{\{MXMID, WordList\}} to the reducer.
    \item Reducer: Keeps track of the dictionary being built up, and given \texttt{\{MXMID, WordList\}} folds up the list of word, for each word updating the dictionary in the following way:
      \[
      \text{\texttt{dict:update(Word, fun(L) -> [MXMID|L] end, [MXMID], Dict)}},
      \]
      that is, either adds \texttt{MXMID} to the list for the given word, or starts a new entry.
  \end{itemize}
\end{description}

\section*{Assessment}
As far as we could determine, our code fulfills the specification and does what we intended it to do. Since the requirements specifically state that error handling is not part of the assignment, we mostly just assume that there will be no errors; specifically, that our mapper processes do not die and that all functions are only used on valid data.

We have used EUnit to implement unit tests for both the general MR skeleton and the MXM functions, all of which succeed. Particularly, we make sure that
\begin{itemize}
  \item the MR skeleton starts and stops coordinator, mapper and reducer threads when we tell it to do so.
  \item the MR skeleton returns correct results for several basic map and reduce functions on simple data sets, and can execute several different tasks in a row.
  \item the functions working on the MXM data set return correct and consistent results: Since the size of the dataset makes it tough to decide if a result is actually correct, we also test on a tiny selfmade dataset where we can manually determine what the correct results are.
  \item all of the above also work for special cases like empty data sets.
\end{itemize}
For more information on the specific tests, see \texttt{mr\_test.erl}. To run all tests, use \texttt{mr\_test:test\_all/0}. Since The tests on the MXM dataset take some time, you should expect this function to run for about 30-50 seconds. In order to test \texttt{grep} with automatical lookup of word stems (see below), run \texttt{mr\_test:mxm\_stems\_test/0}. This test requires the file \texttt{stemmed\_words.txt} to be present in the current directory.

Our MR skeleton is comparatively verbose, which is why we can easily observe any changes in state during the program execution and make sure whatever happens conforms to what we expected. We have used \texttt{pman} to monitor processes during execution for the same reason. There is also an additional command that allows to get additional status information from the coordinator.

We added some very basic error handling/prevention functionality in the sense that we check a few very important inputs for their validity (for example, it is not possible to start the coordinator without starting at least one mapper) and we time out instead of waiting infinitely in the reducer in case some results from the mappers go missing.

All in all, we are confident that our implementation does what we want it to do, and does so in a relatively sensible way.

\section*{Extensions}

\subsection*{Tackling stemmed words}
Given that the words in the word list are stemmed, it might sometimes be difficult to find songs containing a given word, because it does occur and that exact form/conjugation. For instance the word ``behave'' is stemmed to ``behav'', which can be tricky to guess.

On the website for the mxm dataset, one can find a file \texttt{stemmed\_words.txt} giving a mapping of words to their stemmed form. \texttt{grep} can thus be extended by first looking up the stemmed form of the given word, and then using the index of the stemmed word. 

Our \texttt{grep} function accepts as an additional parameter the name of a file containing such a mapping. If a filename is provided, and the specified word cannot be found in the word list as-is, \texttt{grep} will look up a stemmed form in the file.

\subsection*{Error handling}
We've also included a file \texttt{mr\_safer.erl} in which we try to deal with failing mappers and reducers. We introduced a \texttt{supervise} function that loops waiting for exit signals from any of the mappers, reducer or coordinator. If any of them fail we attempt to replace it.

We also register the coordinator by name in order to be able to replace it without the user having to get a hold of the new pid. This also means that the API of \texttt{mr\_safer} is different from the original API.

But our approach does not seem to be very good, since we can only really do something about any of the processes failing when they're idle. When a job is being processed, we cannot reliably do something about it since we don't know (and don't want to keep track of) the exact state of each mapper, each message queue and the reducer all the time, and therefore (so far) we simply fail the entire job. There are certainly more robust alternatives to this, but we never got that far.

\end{document}
